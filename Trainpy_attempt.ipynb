{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37a1d5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d544f342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270000, 5933) (5933,)\n"
     ]
    }
   ],
   "source": [
    "# Loading Data\n",
    "data_train = np.load('data_train.npy')\n",
    "labels_train = np.load('labels_train_corrected.npy')\n",
    "\n",
    "print(data_train.shape, labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49a33e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels Encoding\n",
    "\n",
    "labels_names = ['Nike',\n",
    "                'Adidas',\n",
    "                'Ford',\n",
    "                'Honda',\n",
    "                'General Mills',\n",
    "                'Unilever',\n",
    "                \"McDonald's\",\n",
    "                'KFC',\n",
    "                'Gators',\n",
    "                '3M']\n",
    "\n",
    "labels_names = ['Nike',\n",
    "                'Adidas',\n",
    "                'Ford',\n",
    "                'Honda',\n",
    "                'General_mills',\n",
    "                'Unilever',\n",
    "                \"Mcdonalds\",\n",
    "                'KFC',\n",
    "                'Gators',\n",
    "                '3M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac383b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renii\\AppData\\Local\\Temp\\ipykernel_17736\\3583885791.py:16: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  resized_pil = image_pil.resize(dim, Image.ANTIALIAS)  # Resize using Pillow's resize function\n"
     ]
    }
   ],
   "source": [
    "#Resizing images\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "image_resized = []\n",
    "dim = (64, 64)\n",
    "\n",
    "for i in range(len(data_train.T)):\n",
    "    image = data_train[:, i].reshape((300, 300, 3))\n",
    "\n",
    "    # Convert RGB to BGR\n",
    "    bgr_image = image[..., ::-1]\n",
    "\n",
    "    image_pil = Image.fromarray(bgr_image.astype('uint8'))  # Convert to PIL image\n",
    "    resized_pil = image_pil.resize(dim, Image.ANTIALIAS)  # Resize using Pillow's resize function\n",
    "\n",
    "    # Convert back to BGR\n",
    "    resized_bgr = np.array(resized_pil)\n",
    "    resized_rgb = resized_bgr[..., ::-1]\n",
    "\n",
    "    image_resized.append(resized_rgb)\n",
    "\n",
    "# Convert the list of resized images to a NumPy array\n",
    "image_resized = np.array(image_resized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21c3a865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270000, 5933) (5933,)\n"
     ]
    }
   ],
   "source": [
    "X_train_full = np.load('data_train.npy').T\n",
    "t_train_full = np.load('labels_train_corrected.npy')\n",
    "\n",
    "X_train_full.shape, t_train_full.shape# Loading Data\n",
    "data_train = np.load('data_train.npy')\n",
    "labels_train = np.load('labels_train_corrected.npy')\n",
    "\n",
    "print(data_train.shape, labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d71480d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5043, 270000), (5043,), (4034, 270000), (4034,), (1009, 270000), (1009,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Training and Test sets\n",
    "X_training, X_test, t_training, t_test = train_test_split(X_train_full, \n",
    "                                                  t_train_full, \n",
    "                                                  shuffle=True,\n",
    "                                                  stratify=t_train_full,\n",
    "                                                  test_size=0.15)\n",
    "# Train and validation sets\n",
    "X_train, X_val, t_train, t_val = train_test_split(X_training, \n",
    "                                                  t_training, \n",
    "                                                  shuffle=True,\n",
    "                                                  stratify=t_training,\n",
    "                                                  test_size=0.2)\n",
    "\n",
    "X_training.shape, t_training.shape, X_train.shape, t_train.shape, X_val.shape, t_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f19d758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training_reshaped = X_training.reshape(-1, 300, 300, 3)\n",
    "X_test_reshaped = X_test.reshape(-1, 300, 300, 3)\n",
    "\n",
    "# Reshape the input data to match the model's expected input shape\n",
    "X_train_reshaped = X_train.reshape(-1, 300, 300, 3)\n",
    "X_val_reshaped = X_val.reshape(-1, 300, 300, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea6f6656",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.resnet50.ResNet50(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85dadd34",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'add'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'add'"
     ]
    }
   ],
   "source": [
    "base_model.add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18e7c6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83683744/83683744 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.Xception(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "044ca2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze base model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e52ca5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 150\n",
    "\n",
    "# .Input() instantiates a Keras tensor\n",
    "inputs = keras.Input(shape=(300, 300, 3))\n",
    "# Input layer\n",
    "\n",
    "inputs_resized = tf.keras.layers.Resizing(IMG_SIZE, IMG_SIZE)(inputs)\n",
    "# resizing input to match pretrained model\n",
    "\n",
    "x = base_model(inputs_resized, training=False)\n",
    "# We make sure that the base_model is running in inference mode here,\n",
    "# by passing `training=False`. This is important for fine-tuning, as you will\n",
    "# learn in a few paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c431f2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([None, 300, 300, 3]),\n",
       " TensorShape([None, 150, 150, 3]),\n",
       " TensorShape([None, 5, 5, 2048]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape, inputs_resized.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad3f8887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 51200])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 2: Flattening\n",
    "\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x_flatten = keras.layers.Flatten()(x)\n",
    "\n",
    "x_flatten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e4dc38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Dense classifier with 10 units and softmax activation function\n",
    "outputs = keras.layers.Dense(10, activation='softmax')(x_flatten)\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29aa8043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.functional.Functional"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47d71d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([None, 300, 300, 3]),\n",
       " TensorShape([None, 150, 150, 3]),\n",
       " TensorShape([None, 5, 5, 2048]),\n",
       " TensorShape([None, 10]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape, inputs_resized.shape, x.shape, outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3a1e554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "127/127 [==============================] - 120s 917ms/step - loss: 628.5936 - accuracy: 0.3267 - val_loss: 1041.0428 - val_accuracy: 0.2458\n",
      "Epoch 2/5\n",
      "127/127 [==============================] - 110s 866ms/step - loss: 373.2649 - accuracy: 0.5151 - val_loss: 373.8035 - val_accuracy: 0.5025\n",
      "Epoch 3/5\n",
      "127/127 [==============================] - 113s 892ms/step - loss: 280.9030 - accuracy: 0.6113 - val_loss: 637.2619 - val_accuracy: 0.3479\n",
      "Epoch 4/5\n",
      "127/127 [==============================] - 110s 870ms/step - loss: 249.8238 - accuracy: 0.6492 - val_loss: 478.9712 - val_accuracy: 0.4817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2440b7c1940>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Nadam(learning_rate=0.01, beta_1=0.9, beta_2=0.999),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_reshaped,t_train, epochs=5, batch_size=32,\n",
    "          validation_data=(X_val_reshaped, t_val),\n",
    "          callbacks=[tf.keras.callbacks.EarlyStopping(patience=2)])\n",
    "\n",
    "# Again, in practice, you would run for a lot more epochs. \n",
    "# As well as perform the necessary hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bdfad92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 20s 684ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(890,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label predictions\n",
    "y_test = np.argmax(model.predict(X_test_reshaped),axis=1)\n",
    "\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39361af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "         Nike       0.64      0.32      0.43        90\n",
      "       Adidas       0.57      0.44      0.50        88\n",
      "         Ford       0.65      0.57      0.61        88\n",
      "        Honda       0.77      0.38      0.50        88\n",
      "General_mills       0.64      0.59      0.61        90\n",
      "     Unilever       0.55      0.60      0.58        91\n",
      "    Mcdonalds       0.49      0.40      0.44        88\n",
      "          KFC       0.90      0.10      0.18        88\n",
      "       Gators       0.45      0.65      0.53        88\n",
      "           3M       0.28      0.82      0.42        91\n",
      "\n",
      "     accuracy                           0.49       890\n",
      "    macro avg       0.59      0.49      0.48       890\n",
      " weighted avg       0.59      0.49      0.48       890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(t_test, y_test, target_names=labels_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0579c93c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
